model:
  name: "microsoft/unixcoder-base"  # Can be any CodePTM
  num_prompts: 4
  prompt_length: 8
  max_length: 512
  chunk_size: 512
  stride: 256

stage1:
  epochs: 10
  batch_size: 16
  learning_rate: 2e-5
  classifier_dim: 256

stage2:
  epochs: 5
  batch_size: 8
  learning_rate: 2e-5
  weight_decay: 0.01

training:
  test_size: 0.2
  val_size: 0.15
  device: "auto"

preprocessing:
  remove_comments: true
  remove_extra_lines: true
  extract_neurosymbolic: true

evaluation:
  space_metrics: true
  ksp_simulation: true
  generate_dashboard: true

supported_models:
  - "microsoft/unixcoder-base"
  - "microsoft/codebert-base"
  - "microsoft/graphcodebert-base"
  - "Salesforce/codet5-base"
  - "Salesforce/codet5-large"
  - "Salesforce/codet5p-220m"
  - "codellama/CodeLlama-7b-hf"
  - "google/codegemma-2b"
